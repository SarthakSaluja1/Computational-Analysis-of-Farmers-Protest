---
title: "Topic Models"
author: "Sarthak Saluja"
date: "2022-08-04"
output: html_document
---

Purpose : 

1. Create a separate dfm of tweets 
2. Find optimal topic no.
3. 

Create workspace : 

```{r, message=F}
rm(list= ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(quanteda)
library(stm)
library(topicmodels)
library(dplyr)
library(wordcloud)
library(topicmodels)
library(stm)
library(ggplot2)
library(tidyr)
library(tidytext)
library(ggthemes)
library(furrr)
library(purrr)
library(ldatuning)
library(topicdoc)
#plan(multicore)
```

Load in the data 

```{r}
network_tweets <- readRDS('tweets/network_tweets.rds')
coredfm <- readRDS('dfm/coredfm.rds')
peripherydfm <- readRDS('dfm/peripherydfm.rds')

K_core_results <- readRDS('topic models/K_core_results.rds')
K_periphery_results <- readRDS('topic models/K_periphery_results.rds')

```

Preprocessing :

```{r}
# Get all retweets and only keep the distinct ones whose authors are assigned to a core

retweets <- network_tweets |>
  filter(!is.na(retweeted_text) & !is.na(cores)) |> 
  distinct(referenced_tweets_id.y, .keep_all = T)

# Non retweets

unique_tweets <- network_tweets |> 
  filter(referenced_tweets_type != 'retweeted')

corpus <- bind_rows(original_tweets, retweets) # bind them together

# remove all hashtags 

hashtags <- stringr::str_extract_all(corpus$text.x, "#\\w+")
hashtags <- unlist(hashtags)
hashtags_to_remove <- unique(hashtags)

hashtags_to_remove
```


```{r}
keywords <- c('farmers', 'protest')

make_dfm <- function(tweets = corpus, 
                     core = 1){
  
  dfm <- tweets |> 
    filter(!is.na(cores) & 
             referenced_tweets_type != 'retweeted' & 
             is_core == core) |> 
    corpus(text = 'text.x') |> 
    tokens(remove_punct = TRUE, 
           remove_symbols = TRUE, 
           remove_numbers = TRUE, 
           remove_url = TRUE) |> 
    tokens_remove(c(stopwords('en'), 
                    hashtags_to_remove, 
                    keywords)) |> 
    tokens_ngrams(1:2) |>
    dfm() |>
    dfm_group(groups = created_at) |>
    dfm_trim(min_termfreq = 20, 
             max_termfreq = 1000)
  
  return(dfm)
}

coredfm <- make_dfm(corpus, core = 1)
peripherydfm <- make_dfm(corpus, core = 0)

saveRDS(coredfm, 'dfm/coredfm.rds')
saveRDS(peripherydfm, 'dfm/peripherydfm.rds')

coredfm
peripherydfm
```

Evaluate and chose : 

```{r}
options(scipen = 99)

# Evaluate topic models

tm_input <- convert(dfm, to = 'tm')

K = c(30, 40, 50, 60, 70, 80, 90, 100)

# Log likelihood and exclusivity metric

metrics <- lapply(1:length(K), function(x){
  
  K = K[x]
  print(K)
  
  tm_core <- LDA(core_input, 
            K, 
            method="Gibbs", 
            control=list(iter = 50, seed = 21))
  
  tm_periphery <- LDA(periphery_input, 
                 K, 
                 method="Gibbs", 
                 control=list(iter = 50, seed = 11))
  
  
  log_likelihood_core <- as.numeric(logLik(tm_core))
  log_likelihood_periphery <- as.numeric(logLik(tm_periphery))
  
  exclusivity_core <- mean(topic_exclusivity(tm_core))
  exclusivity_periphery <- mean(topic_exclusivity(tm_periphery))
  
  return(list(log_likelihood_core, log_likelihood_periphery, 
              exclusivity_core, exclusivity_periphery))
})


metrics <- data.frame(K, do.call(rbind, metrics))
metrics <- unnest(metrics)
colnames(metrics) <- c('K', 'LL_Core', 'LL_Periphery', 'exclusivity_Core', 'exclusivity_Periphery')

saveRDS(metrics, 'topic models/evaluation_results.rds')

```

Show metrics : 

```{r}
ptm_chose <- metrics |> 
  pivot_longer(cols = -K, 
               names_to = c('metric', '.values'),
               names_sep = '_') |>
  filter(.values == 'Periphery') |>
  ggplot() + 
  geom_line(aes(x = K, y = value), 
            color = '#46A6C3') + 
  geom_point(aes(x = K, y = value), 
            color = '#46A6C3') +
  facet_wrap(~metric, 
             scales = 'free') + 
  theme_bw() + 
  labs(title = 'Evaluation metrics : Periphery')

ctm_chose <- metrics |> 
  pivot_longer(cols = -K, 
               names_to = c('metric', '.values'),
               names_sep = '_') |>
  filter(.values == 'Core') |>
  ggplot() + 
  geom_line(aes(x = K, y = value), 
            color = '#1E4E5C') + 
  geom_point(aes(x = K, y = value), 
            color = '#1E4E5C') +
  facet_wrap(~metric, 
             scales = 'free') + 
  theme_bw() + 
  labs(title = 'EValuation metrics : Core')

ptm_chose
ctm_chose

ggsave('plots/topic models/chose_core.png', ctm_chose)
ggsave('plots/topic models/chose_periphery.png', ptm_chose)

```


```{r}
ctm <- LDA(core_input, 
           100, 
           method="Gibbs", 
           control=list(iter = 500, seed = 1))

ptm <- LDA(periphery_input, 
           100, 
           method="Gibbs", 
           control=list(iter = 500, seed = 11))

```


Analyze top terms for each topic : 

```{r}
core_terms <- data.frame(t(data.frame(terms(ctm, 20))))
periphery_terms <- data.frame(t(data.frame(terms(ptm, 20))))


core_labels <- data.frame(topics = 1:100, 
           terms = do.call(paste, c(core_terms, sep=", ")))


periphery_labels <- data.frame(topics = 1:100, 
           terms = do.call(paste, c(periphery_terms, sep=", ")))


write.csv(core_labels, 'topic models/core_labels.csv', 
          row.names = F)

write.csv(periphery_labels, 'topic models/periphery_labels.csv', 
          row.names = F)
```

Beta/Gamma values : 

```{r}
gamma_core <- tidy(ctm, 
                   matrix = 'gamma')

gamma_periphery <- tidy(ptm, 
                   matrix = 'gamma')


saveRDS(gamma_core, 'topic models/gamma_core.rds')
saveRDS(gamma_core, 'topic models/gamma_periphery.rds')

```

Matching Topics : 

```{r}
select_topic <- function(topic_core, 
                          topic_periphery, 
                          topic_name, 
                          save = NULL){
  core <- gamma_core |>
    filter(topic == topic_core) |> 
    mutate(name = topic_name) |> 
    select(document, name, gamma)
  
  periphery <- gamma_periphery |>
    filter(topic == topic_periphery) |> 
    mutate(name = topic_name) |> 
    select(document, name, gamma)
  
  topic <- core |> 
    full_join(periphery, by = 'document') |> 
    select(document, gamma_core = gamma.x, gamma_periphery = gamma.y, name = name.x)
  
  
  if(save == T){
    write.csv(topic, paste0('topics/', topic_name, '.csv'))
    return(topic)
  }else(
    return(topic)
  )
}


suppress <- select_topic(topic_core = 44, 
                       topic_periphery = 34, 
                       topic_name = 'suppress', 
                       save = T)


singhu <- select_topic(topic_core = 45, 
                       topic_periphery = 18, 
                       topic_name = 'singhu', 
                       save = T)

rihanna <- select_topic(topic_core = 58, 
                       topic_periphery = 25, 
                       topic_name = 'rihanna', 
                       save = T)

republic_day <- select_topic(topic_core = 68, 
                       topic_periphery = 91, 
                       topic_name = 'republic day', 
                       save = T)

crony <- select_topic(topic_core = 71, 
                       topic_periphery = 31, 
                       topic_name = 'crony capitalism', 
                       save = T)

media <- select_topic(topic_core = 81, 
                       topic_periphery = 21, 
                       topic_name = 'media hypocracy', 
                       save = T)

covid <- select_topic(topic_core = 96, 
                       topic_periphery = 77, 
                       topic_name = 'covid', 
                       save = T)

```







